# Default values for kafka-exporter.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: danielqsj/kafka-exporter
  tag: latest
  pullPolicy: IfNotPresent

nameOverride: ""
fullnameOverride: ""

service:
  type: ClusterIP
  port: 9308

kafkaExporter:
  kafka:
    servers: []
      # - kafka:9092
    # version: "1.0.0"

  sasl:
    enabled: false
    handshake: true
    username: ""
    password: ""
    mechanism: ""

  tls:
    enabled: false
    insecureSkipTlsVerify: false
    caFile: ""
    certFile: ""
    keyFile: ""

  log:
    verbosity: 0
    enableSarama: false

prometheus:
  serviceMonitor:
    enabled: true
    namespace: monitoring
    interval: "30s"
    additionalLabels:
      app: kafka-exporter
    metricRelabelings: {}

labels: {}
podLabels: {}

# Adds in Datadog annotations needed to scrape the prometheus endpoint.
# prefix is required. If added, will provide a metric such as test.kafka_brokers.
# Example metrics below. map metric name to a potential new metric name in dd.
datadog:
  use_datadog: false
  prefix: <dd_prefix>
  metrics: [
    {"kafka_brokers": "kafka_brokers"},
    {"kafka_consumergroup_lag": "kafka_consumergroup_lag"},
    {"kafka_consumergroup_current_offset": "kafka_consumergroup_current_offset"}
    ]

# Add support for azure managed prometheus by creating service monitor with the supported api group
azuremanagedprometheus:
  use_azuremanagedprometheus: false

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}
